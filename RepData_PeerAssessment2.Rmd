---
title: "R Notebook Reproducible Research Peer Assessment 2"
output:
  html_document:
    df_print: paged
---

# Enviroment set up.
Below are the libraries used for this session in R. 
```{r, echo=FALSE, results="hide", include=FALSE}
  # Enviroment 
  # Loading and preprocessing the data
  #Set up enviroment for R scrip  
  # Packages for tidyverse 
    library("tidyverse")
    library("lubridate")
  # Package for building tables in markdown and notebook 
    library("knitr")
    library("kableExtra") 
    library("xtable")
  # Package for forecasting
    library("fpp2")
  # Packages for reading excel and html files and XML
    library("openxlsx")
    library("XML")
  # Parkage for using data tables for very large data operations
    library("data.table")
  #Package for reading fixed width tables
    library("utils")
  # Packages for reading data through API's 
    library("httr")
    library("jsonlite")
  # Package for performing inquires with SQL databases 
    library("sqldf")
  #Package for reading and writing to jpeg files
    library("jpeg")

# Set proper working Dir
if (!getwd() == "C:/Users/paulr/Documents/R/Coursera_ReproducibleResearch/RepData_PeerAssessment2") {setwd("./Coursera_ReproducibleResearch/RepData_PeerAssessment2")}

# Check for data directory and if one is not present then make it
if (!file.exists("data")) {
  dir.create("data")
}

```
# Data Processing  

Data is first aquired from the web and then placed into a data directory. Following that I make a dataframe and then take some looks to gage size and layout before trimming down the columns for workability and set up a file called "storm_health_cost". The data is caputred directly from the website lined in the assigment page. 
```{r, echo=TRUE, results=FALSE, cache=TRUE, include=FALSE}

# File to retreve from the internet: https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2
# Download data using a URL into th data directory
fileUrl <- "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
download.file(fileUrl, destfile = "./data/repdata_data_StormData.csv.bz2")
dateDownloaded <- date()
dateDownloaded
list.files("./data")

stormdata <- read_csv("./data/repdata_data_StormData.csv.bz2", col_names = TRUE)
stormdata %>% select(EVTYPE, STATE__, BGN_DATE, COUNTYNAME, FATALITIES, INJURIES, PROPDMG, PROPDMGEXP, CROPDMG, CROPDMGEXP) -> storm_health_cost
storm_health_cost$BGN_DATE <- date(mdy_hms(storm_health_cost$BGN_DATE))
    
```

# Data Transformations and Analysis
Becuase we have a ery large dataset I will remove the NA's. I also filtered by date and selected the top 10 events by fatalities, injuries, and cost. 
```{r, echo=TRUE, results=FALSE, cache=TRUE, include=TRUE}

# Analysing the health impacts of storm events
glimpse(storm_health_cost) -> storm_health_cost_structure
#str(storm_health_cost)
storm_health_cost %>% select(-CROPDMGEXP) -> storm_health_cost
#Look at date ranges
#summary(storm_health_cost$BGN_DATE)
storm_health_cost %>% filter(BGN_DATE > ymd("2001-11-1")) -> storm_health_cost

# Make a summerized data frame for final plot and table results 
storm_health_cost %>% select(EVTYPE, BGN_DATE, FATALITIES, INJURIES) %>%
  mutate(Both = FATALITIES + INJURIES) %>% group_by(EVTYPE) %>% 
  summarise(Fatalities = sum(FATALITIES), Injuries = sum(INJURIES), Both = sum(Both)) %>% arrange(desc(Both)) -> Health1

# Top Events by Fatalities
Health1 %>% arrange(desc(Fatalities)) -> HealthFat

# Top Events by Injuries
Health1 %>% arrange(desc(Injuries)) -> HealthInj

# Top Events by Both
Health1 %>% arrange(desc(Both))  -> HealthBoth
HealthBoth[1:10, ] ->Top10Events
Top10Events %>% select(EVTYPE, Both, Fatalities, Injuries) %>%
gather(Key, value, -EVTYPE) -> Top10Events

ComparativeHealth <- data.frame('Rank' = 1:10, 'Fatalities' = HealthFat[1:10,1], 'Injuries' = HealthInj[1:10,1], Both = HealthBoth[1:10, 1])
names(ComparativeHealth) <- c("Rank", "Fatalities", "Injuries", "Both")

# Analysing the cost impacts of storm events

Propdmgexp_LU <-data.frame("PROPDMGEXP" = unique(storm_health_cost$PROPDMGEXP), "PropExp" = c(1000, 1000000, 1, 1000000000, 1), stringsAsFactors = FALSE) 

left_join(storm_health_cost, Propdmgexp_LU, by="PROPDMGEXP") %>% mutate( DmgCost = PROPDMG * PropExp) %>% select(EVTYPE, DmgCost) %>% group_by(EVTYPE) %>% summarise(Cost = sum(DmgCost)) %>% arrange(desc(Cost)) %>% transmute(EVTYPE, Cost_x_B = Cost/1000000000) ->  ComparativeCost
ComparativeCost <- ComparativeCost[1:10,]
ComparativeCost$Cost_x_B <- round(ComparativeCost$Cost_x_B)


```


# Results 
Tables and plots are provided showing the combination of health effects and cost do demonstrate what the worse grouping of evenats are. 
```{r, echo=TRUE, results=TRUE, cache=TRUE, include=TRUE}
kable(ComparativeHealth, format = "html", align = 'llll', caption = "Comparitive Ranking in decreasing impact order by type" ) %>% kable_styling(bootstrap_options = "striped", full_width = F)


Top10Events %>% ggplot(aes(x = EVTYPE, y = value, fill = Key)) +
  geom_col(position = "dodge") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  labs(title = "Comparitive of Events by fatalities and injuries", y="Counts", x="Events")
  
kable(ComparativeCost, format = "html", align = 'll', caption = "Comparitive Ranking in decreasing impact order by Cost" ) %>% kable_styling(bootstrap_options = "striped", full_width = F)

ComparativeCost %>% ggplot(aes(x = EVTYPE, y = Cost_x_B)) +
  geom_col(fill="blue") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  labs(title = "Comparision by Cost", y="Costs", x="Events")
```






